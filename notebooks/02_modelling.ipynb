{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b003b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad73d156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5753, 18),\n",
       " missed_any\n",
       " 0    0.608726\n",
       " 1    0.391274\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed modelling table\n",
    "model_df = pd.read_csv(\"../data/processed/child_mom_model_table.csv\")\n",
    "\n",
    "# Vaccine columns you used before\n",
    "vaccine_cols = [\"bcg\", \"dpt1\", \"dpt2\", \"dpt3\",\n",
    "                \"polio0\", \"polio1\", \"polio2\", \"polio3\", \"measles1\"]\n",
    "\n",
    "# Treat missing vaccine info as \"not received\"\n",
    "model_df[vaccine_cols] = model_df[vaccine_cols].fillna(0)\n",
    "\n",
    "target_col = \"missed_any\"\n",
    "id_cols = [\"cluster\", \"household\", \"woman_line\"]\n",
    "\n",
    "X = model_df.drop(columns=id_cols + [target_col])\n",
    "y = model_df[target_col].astype(int)\n",
    "\n",
    "X.shape, y.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9824ac12",
   "metadata": {},
   "source": [
    "02 – Modelling: predicting missed vaccinations\n",
    "\n",
    "Goal: build and compare predictive models for `missed_any` using the features\n",
    "prepared in `01_eda.ipynb`. We will:\n",
    "\n",
    "- Train a baseline logistic regression model.\n",
    "- Train a stronger tree-based model (Random Forest).\n",
    "- Use stratified train/test split and cross-validation.\n",
    "- Compare ROC AUC, recall for `missed_any = 1`, and confusion matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc4063b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4602, 18), (1151, 18))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratified split to keep class balance similar in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b0c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Fit model, print metrics, and return a results dict.\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba),\n",
    "        \"recall_pos\": classification_report(\n",
    "            y_test, y_pred, output_dict=True\n",
    "        )[\"1\"][\"recall\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672a762c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       701\n",
      "           1       0.90      0.83      0.86       450\n",
      "\n",
      "    accuracy                           0.90      1151\n",
      "   macro avg       0.90      0.88      0.89      1151\n",
      "weighted avg       0.90      0.90      0.89      1151\n",
      "\n",
      "ROC AUC: 0.9484688540180695\n",
      "Confusion matrix:\n",
      " [[658  43]\n",
      " [ 77 373]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=5000, class_weight=None)\n",
    ")\n",
    "\n",
    "results = []\n",
    "results.append(evaluate_model(\"Logistic Regression\", log_reg, X_train, X_test, y_train, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "040ddf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       701\n",
      "           1       0.96      0.97      0.96       450\n",
      "\n",
      "    accuracy                           0.97      1151\n",
      "   macro avg       0.97      0.97      0.97      1151\n",
      "weighted avg       0.97      0.97      0.97      1151\n",
      "\n",
      "ROC AUC: 0.9923395149786021\n",
      "Confusion matrix:\n",
      " [[681  20]\n",
      " [ 14 436]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "results.append(evaluate_model(\"Random Forest\", rf, X_train, X_test, y_train, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98cd1805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>recall_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.948469</td>\n",
       "      <td>0.828889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>0.968889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model   roc_auc  recall_pos\n",
       "0  Logistic Regression  0.948469    0.828889\n",
       "1        Random Forest  0.992340    0.968889"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f90c9dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression – CV\n",
      "CV AUC scores: [0.94753368 0.96288477 0.96146341 0.94293333 0.94673651]\n",
      "Mean CV AUC: 0.9523103411475118\n",
      "\n",
      "Random Forest – CV\n",
      "CV AUC scores: [0.9863988  0.99284514 0.99262274 0.98947302 0.99099365]\n",
      "Mean CV AUC: 0.9904666694019479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def cv_auc(model, X, y, cv):\n",
    "    scores = cross_val_score(\n",
    "        model, X, y,\n",
    "        cv=cv,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    print(\"CV AUC scores:\", scores)\n",
    "    print(\"Mean CV AUC:\", scores.mean())\n",
    "    return scores\n",
    "\n",
    "print(\"Logistic Regression – CV\")\n",
    "_ = cv_auc(log_reg, X, y, cv)\n",
    "\n",
    "print(\"\\nRandom Forest – CV\")\n",
    "_ = cv_auc(rf, X, y, cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fea56ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dob_cmc</td>\n",
       "      <td>0.361723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>n_received</td>\n",
       "      <td>0.162813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>measles1</td>\n",
       "      <td>0.137835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>polio3</td>\n",
       "      <td>0.055005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>polio2</td>\n",
       "      <td>0.043175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dpt3</td>\n",
       "      <td>0.032828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bcg</td>\n",
       "      <td>0.031629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dpt1</td>\n",
       "      <td>0.030548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.025824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>region</td>\n",
       "      <td>0.022563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>polio1</td>\n",
       "      <td>0.021185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dpt2</td>\n",
       "      <td>0.020704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>polio0</td>\n",
       "      <td>0.015693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wealth_quintile</td>\n",
       "      <td>0.014083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>births_5yrs</td>\n",
       "      <td>0.009124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  importance\n",
       "0           dob_cmc    0.361723\n",
       "17       n_received    0.162813\n",
       "16         measles1    0.137835\n",
       "15           polio3    0.055005\n",
       "14           polio2    0.043175\n",
       "11             dpt3    0.032828\n",
       "8               bcg    0.031629\n",
       "9              dpt1    0.030548\n",
       "2               age    0.025824\n",
       "4            region    0.022563\n",
       "13           polio1    0.021185\n",
       "10             dpt2    0.020704\n",
       "12           polio0    0.015693\n",
       "6   wealth_quintile    0.014083\n",
       "7       births_5yrs    0.009124"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rf_feature_importance = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance\": rf.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "rf_feature_importance.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb3449",
   "metadata": {},
   "source": [
    "Model comparison summary\n",
    "\n",
    "We compared two models using the same train/test split and 5-fold cross-validation:\n",
    "\n",
    "- Logistic Regression (with StandardScaler)  \n",
    "  - Test ROC AUC ≈ 0.95  \n",
    "  - Recall for `missed_any` ≈ 0.83  \n",
    "  - Mean CV ROC AUC ≈ 0.95\n",
    "\n",
    "- Random Forest  \n",
    "  - Test ROC AUC ≈ 0.99  \n",
    "  - Recall for `missed_any` ≈ 0.97  \n",
    "  - Mean CV ROC AUC ≈ 0.99\n",
    "\n",
    "Random Forest clearly outperforms logistic regression, especially on recall for missed vaccinations, which is critical if the goal is to identify as many at-risk children as possible. Feature importance shows that child age (`dob_cmc`), total number of doses received (`n_received`), and measles/polio/dpt doses carry most of the predictive signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd802ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Probabilities from the fitted Random Forest\n",
    "rf_proba = rf.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fa0d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.3 -> precision=0.938, recall=0.978\n",
      "Threshold 0.5 -> precision=0.956, recall=0.969\n",
      "Threshold 0.7 -> precision=0.971, recall=0.909\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.3, 0.5, 0.7]\n",
    "\n",
    "for thr in thresholds:\n",
    "    rf_pred_thr = (rf_proba >= thr).astype(int)\n",
    "    prec = precision_score(y_test, rf_pred_thr)\n",
    "    rec = recall_score(y_test, rf_pred_thr)\n",
    "    print(f\"Threshold {thr:.1f} -> precision={prec:.3f}, recall={rec:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257fdc99",
   "metadata": {},
   "source": [
    "Threshold analysis for Random Forest (missed_any = 1)\n",
    "\n",
    "Using the RandomForest model’s predicted probabilities on the test set:\n",
    "\n",
    "| Threshold | Precision (missed_any=1) | Recall (missed_any=1) |\n",
    "|----------|---------------------------|------------------------|\n",
    "| 0.3      | 0.938                     | 0.978                  |\n",
    "| 0.5      | 0.956                     | 0.969                  |\n",
    "| 0.7      | 0.971                     | 0.909                  |\n",
    "\n",
    "Interpretation\n",
    "\n",
    "- Lowering the decision threshold from 0.5 → 0.3 slightly reduces precision (0.956 → 0.938) but increases recall from 0.969 to 0.978 – we catch more children who truly missed at least one dose.\n",
    "- Raising the threshold to 0.7 gives only a small gain in precision (0.971) but recall drops to 0.909, meaning more children who actually missed vaccinations would not be flagged.\n",
    "- For a real reminder system, recall is more critical than squeezing out the last bit of precision. A threshold around 0.3–0.4 is therefore more appropriate if the programme’s priority is to minimise the risk of leaving out children who need follow-up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae2155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
